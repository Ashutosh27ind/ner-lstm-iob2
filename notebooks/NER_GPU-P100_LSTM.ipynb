{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8413454,"sourceType":"datasetVersion","datasetId":5007705}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T19:18:51.162435Z","iopub.execute_input":"2024-05-14T19:18:51.162949Z","iopub.status.idle":"2024-05-14T19:18:52.068307Z","shell.execute_reply.started":"2024-05-14T19:18:51.162920Z","shell.execute_reply":"2024-05-14T19:18:52.067190Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ner-data/ner_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pandas numpy scikit-learn keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:18:52.070146Z","iopub.execute_input":"2024-05-14T19:18:52.070712Z","iopub.status.idle":"2024-05-14T19:19:08.081807Z","shell.execute_reply.started":"2024-05-14T19:18:52.070678Z","shell.execute_reply":"2024-05-14T19:19:08.080849Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install pandas numpy scikit-learn keras tensorflow\n# Used GPU P100 (Kaggle Kernel)\n\nimport logging\nimport os\nimport random\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Embedding, Dense, Dropout, BatchNormalization\nfrom sklearn.metrics import classification_report, f1_score\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nimport traceback\nimport spacy\nfrom spacy import displacy\n\n# Configure logging\nlog_dir = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), 'logs')\nos.makedirs(log_dir, exist_ok=True)\nlogging.basicConfig(\n    filename=os.path.join(log_dir, 'app.log'),\n    level=logging.INFO,\n    format='%(asctime)s [%(levelname)s]: %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\n\n# Suppress deprecation warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n'''\n# Load the dataset\ndata_directory = os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)), 'data')\ndataset_path = os.path.join(data_directory, 'ner_dataset.csv')\nif os.path.exists(dataset_path):\n    df_ner = pd.read_csv(dataset_path, encoding=\"latin1\")\nelse:\n    logging.error(f\"Dataset not found at: {dataset_path}\")\n'''\n\n# Check if GPU is available\nif tf.test.is_gpu_available():\n    print(\"GPU is available!!\")\n    device = '/gpu:0'\nelse:\n    print(\"GPU not available, using CPU instead!\")\n    device = '/cpu:0'\n\n\ndf_ner = pd.read_csv('/kaggle/input/ner-data/ner_dataset.csv', encoding=\"latin1\")\n\n# Drop unnecessary columns\ndf_ner = df_ner.drop(columns=[\"POS\"])\n\nprint(df_ner)\n\n# we'll preprocess the data by creating a function to transform the dataset into sentences and corresponding labels:\n\ndef preprocess_data(data):\n    \"\"\"\n    Preprocesses the NER dataset into sentences and corresponding labels.\n\n    Args:\n    data: pandas DataFrame containing the NER dataset\n\n    Returns:\n    sentences: list of lists containing words for each sentence\n    labels: list of lists containing NER labels for each sentence\n    \"\"\"\n    sentences = []\n    labels = []\n    current_sentence = []\n    current_labels = []\n\n    for index, row in data.iterrows():\n        # If it's the start of a new sentence\n        if pd.isnull(row['Sentence #']):\n            sentences.append(current_sentence)\n            labels.append(current_labels)\n            current_sentence = []\n            current_labels = []\n        else:\n            current_sentence.append(row['Word'])\n            current_labels.append(row['Tag'])\n    \n    print(\"Preprocessing is Completed !!\")\n    return sentences, labels\n\nsentences, labels = preprocess_data(df_ner)\n\n# Now, let's split the dataset into train, validation, and test sets:\n\n# Split the data into train and test sets (80% train, 20% test)\ntrain_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n\n# Further split the train set into train and validation sets (80% train, 20% validation)\ntrain_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences, train_labels, test_size=0.2, random_state=42)\n\n# With the data preprocessed and split, we can now move on to building the baseline model. We'll use a simple LSTM-based model for this:\n\n# Tokenize words and labels\nwords = list(set(df_ner[\"Word\"].values))\nn_words = len(words)\n\ntags = list(set(df_ner[\"Tag\"].values))\nn_tags = len(tags)\n\n# Create mappings for words and tags\nword2idx = {w: i for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}\n\n# Padding sequences\nmax_len = 50\nX_train = [[word2idx[w] for w in s] for s in train_sentences]\nX_train = pad_sequences(maxlen=max_len, sequences=X_train, padding=\"post\", value=n_words-1)\n\ny_train = [[tag2idx[t] for t in l] for l in train_labels]\ny_train = pad_sequences(maxlen=max_len, sequences=y_train, padding=\"post\", value=tag2idx[\"O\"])\ny_train = [to_categorical(i, num_classes=n_tags) for i in y_train]\n\ntry:\n    with tf.device(device):\n        \n        # Define the model architecture\n        model = Sequential()\n        model.add(Embedding(input_dim=n_words, output_dim=10, input_length=max_len))\n        model.add(LSTM(units=20, return_sequences=True, recurrent_dropout=0.1))\n        model.add(Dropout(0.5))  # Added dropout for regularization\n        model.add(Dense(n_tags, activation=\"softmax\"))\n        \n        # Compile model\n        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n        \n        # print model summary\n        print(model.summary())\n        plot_model(model)\n\n        # Define early stopping\n        early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n\n        # Define model checkpointing\n        checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n        \n        # Larger batch size\n        batch_size = 256  # Adjust based on your GPU memory\n\n        # Train the model\n        model.fit(X_train, np.array(y_train), batch_size=batch_size, epochs=5, validation_split=0.1, verbose=1, callbacks=[early_stopping, checkpoint])\n\nexcept Exception as e:\n    logging.error(\"Exception occurred\", exc_info=True)\n    traceback.print_exc()\n\n#This code sets up a basic LSTM-based model for NER, tokenizes words and labels, pads sequences, defines the model architecture, compiles the model, and finally trains it.\n\n# Prepare the test data\nX_test = [[word2idx.get(w, n_words-1) for w in s] for s in test_sentences]\nX_test = pad_sequences(maxlen=max_len, sequences=X_test, padding=\"post\", value=n_words-1)\n\ny_test = [[tag2idx.get(t, tag2idx[\"O\"]) for t in l] for l in test_labels]\ny_test = pad_sequences(maxlen=max_len, sequences=y_test, padding=\"post\", value=tag2idx[\"O\"])\ny_test = [to_categorical(i, num_classes=n_tags) for i in y_test]\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Convert the index to tag\nidx2tag = {i: w for w, i in tag2idx.items()}\n\ndef pred2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            p_i = np.argmax(p)\n            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n        out.append(out_i)\n    return out\n\npred_labels = pred2label(y_pred)\ntest_labels = pred2label(y_test)\n\n# Flatten the lists of labels and predictions\nflat_test_labels = [label for sublist in test_labels for label in sublist]\nflat_pred_labels = [label for sublist in pred_labels for label in sublist]\n\n# Print the classification report\n#print(classification_report(test_labels, pred_labels))\n\n# Calculate the F1 score\nf1 = f1_score(flat_test_labels, flat_pred_labels, average='weighted')\n\nprint(f'F1 Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T19:19:08.083553Z","iopub.execute_input":"2024-05-14T19:19:08.083917Z","iopub.status.idle":"2024-05-14T19:47:04.155739Z","shell.execute_reply.started":"2024-05-14T19:19:08.083875Z","shell.execute_reply":"2024-05-14T19:47:04.154674Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-14 19:19:10.309173: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 19:19:10.309275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 19:19:10.430485: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"GPU is available!!\n          Sentence #           Word Tag\n0        Sentence: 1      Thousands   O\n1                NaN             of   O\n2                NaN  demonstrators   O\n3                NaN           have   O\n4                NaN        marched   O\n...              ...            ...  ..\n1048570          NaN           they   O\n1048571          NaN      responded   O\n1048572          NaN             to   O\n1048573          NaN            the   O\n1048574          NaN         attack   O\n\n[1048575 rows x 3 columns]\nPreprocessing is Completed !!\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 50, 10)            351780    \n                                                                 \n lstm (LSTM)                 (None, 50, 20)            2480      \n                                                                 \n dropout (Dropout)           (None, 50, 20)            0         \n                                                                 \n dense (Dense)               (None, 50, 17)            357       \n                                                                 \n=================================================================\nTotal params: 354617 (1.35 MB)\nTrainable params: 354617 (1.35 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nNone\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715714447.820048     110 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"2252/2252 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9976\nEpoch 1: val_loss improved from inf to 0.00102, saving model to model.keras\n2252/2252 [==============================] - 273s 119ms/step - loss: 0.0742 - accuracy: 0.9976 - val_loss: 0.0010 - val_accuracy: 0.9997\nEpoch 2/5\n2252/2252 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998\nEpoch 2: val_loss improved from 0.00102 to 0.00086, saving model to model.keras\n2252/2252 [==============================] - 263s 117ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 8.6432e-04 - val_accuracy: 0.9998\nEpoch 3/5\n2252/2252 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\nEpoch 3: val_loss improved from 0.00086 to 0.00080, saving model to model.keras\n2252/2252 [==============================] - 267s 119ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 7.9688e-04 - val_accuracy: 0.9998\nEpoch 4/5\n2252/2252 [==============================] - ETA: 0s - loss: 7.8594e-04 - accuracy: 0.9998\nEpoch 4: val_loss improved from 0.00080 to 0.00062, saving model to model.keras\n2252/2252 [==============================] - 271s 121ms/step - loss: 7.8594e-04 - accuracy: 0.9998 - val_loss: 6.2103e-04 - val_accuracy: 0.9998\nEpoch 5/5\n2252/2252 [==============================] - ETA: 0s - loss: 5.1422e-04 - accuracy: 0.9999\nEpoch 5: val_loss improved from 0.00062 to 0.00040, saving model to model.keras\n2252/2252 [==============================] - 268s 119ms/step - loss: 5.1422e-04 - accuracy: 0.9999 - val_loss: 3.9590e-04 - val_accuracy: 0.9999\n6254/6254 [==============================] - 86s 14ms/step\nF1 Score: 0.9998776739095787\n","output_type":"stream"}]}]}